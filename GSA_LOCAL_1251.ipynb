{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSA with SOBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "C:\\Users\\shrid\\Anaconda3\\lib\\site-packages\\ema_workbench\\analysis\\prim.py:31: ImportWarning: altair based interactive inspection not available\n  \"inspection not available\"), ImportWarning)\nC:\\Users\\shrid\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n"
    }
   ],
   "source": [
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "# import statsmodels.api as sm\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, IntegerParameter, ArrayOutcome, TimeSeriesOutcome,\n",
    "                           ema_logging, SequentialEvaluator,\n",
    "                           MultiprocessingEvaluator)\n",
    "from ema_workbench import save_results, load_results\n",
    "# from ema_workbench.analysis import prim\n",
    "from ema_workbench.analysis import scenario_discovery_util as sdutil\n",
    "from sklearn import preprocessing \n",
    "from ema_workbench.em_framework.evaluators import LHS, SOBOL, MORRIS\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "from dicemodel.noDICE_v2 import PyDICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openExp_working import dice_sm.uncertainties, dice_sm.levers, dice_sm.outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "    \n",
    "\n",
    "    model = PyDICE()\n",
    "    dice_sm = Model('dicesmEMA', function=model)\n",
    "    \n",
    "    dice_sm.uncertainties = [IntegerParameter('t2xco2_index', 0, 999),\n",
    "                             IntegerParameter('t2xco2_dist',0,2),\n",
    "                             IntegerParameter('fdamage', 0, 2),\n",
    "                             RealParameter('tfp_gr',  0.07, 0.09),\n",
    "                             RealParameter('sigma_gr', -0.012, -0.008),\n",
    "                             RealParameter('pop_gr', 0.1, 0.15),\n",
    "                             RealParameter('emdd',  0.01, 2.00),\n",
    "                             RealParameter('fosslim',  4000.0, 13649),\n",
    "                             IntegerParameter('cback', 100, 600)]\n",
    "    \n",
    "    dice_sm.levers = [RealParameter('sr', 0.1, 0.5),\n",
    "                      RealParameter('prtp_con',  0.001, 0.015),\n",
    "                      RealParameter('prtp_dam',  0.001, 0.015),\n",
    "                    #   RealParameter('emuc',  0.01, 2.00),                      \n",
    "                      IntegerParameter('periodfullpart', 10, 58),\n",
    "                      IntegerParameter('miu_period', 10, 58)]\n",
    "    \n",
    "    dice_sm.outcomes = [TimeSeriesOutcome('Atmospheric Temperature'),\n",
    "                        TimeSeriesOutcome('Damages'),\n",
    "                        TimeSeriesOutcome('Utility of Consumption'),\n",
    "                        TimeSeriesOutcome('Disutility of Damage'),\n",
    "                        # TimeSeriesOutcome('Damage to output ratio'),\n",
    "                        TimeSeriesOutcome('Welfare'),\n",
    "                        TimeSeriesOutcome('Total Output'),\n",
    "                        TimeSeriesOutcome('Consumption SDR'),\n",
    "                        TimeSeriesOutcome('Damage SDR')\n",
    "                        ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'num_vars': 9,\n 'names': ['cback',\n  'emdd',\n  'fdamage',\n  'fosslim',\n  'pop_gr',\n  'sigma_gr',\n  't2xco2_dist',\n  't2xco2_index',\n  'tfp_gr'],\n 'bounds': [(100, 601),\n  (0.01, 2.0),\n  (0, 3),\n  (4000.0, 13649),\n  (0.1, 0.15),\n  (-0.012, -0.008),\n  (0, 3),\n  (0, 1000),\n  (0.07, 0.09)]}"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "problem = get_SALib_problem(dice_sm.uncertainties)\n",
    "problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scenarios = 100\n",
    "n_policies = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[MainProcess/INFO] pool started\n[MainProcess/INFO] performing 2000 scenarios * 50 policies * 1 model(s) = 100000 experiments\n[MainProcess/INFO] 10000 cases completed\n[MainProcess/INFO] 20000 cases completed\n[MainProcess/INFO] 30000 cases completed\n[MainProcess/INFO] 40000 cases completed\n[MainProcess/INFO] 50000 cases completed\n[MainProcess/INFO] 60000 cases completed\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "with MultiprocessingEvaluator(dice_sm) as evaluator:\n",
    "       results_sobol = evaluator.perform_experiments(n_scenarios, n_policies, uncertainty_sampling=SOBOL)\n",
    "end = time.time()\n",
    "\n",
    "print('Experiment time is ' + str(round((end - start)/60)) + ' mintues')\n",
    "# Num of runs needed for k uncertainties = 1000(k+2)\n",
    "# for 9 uncertainties, 11,000 runs\n",
    "# with 100 scenarios and 10 policies under sobol, we get 18000 experiments/ runs (now 20,000: how does this work?)\n",
    "#  1000s, 100p = 2million experiments. starting time 1:13 am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_results(results_sobol, '2a_SOBOL_100s_50p_100000e_fdamage.tar.gz')\n",
    "#results = load_results('SOBOL_160s_10p.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(results_sobol)\n",
    "experiments, outcomes = results_sobol\n",
    "# outcomes\n",
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# results_sobol_df = pd.DataFrame(results_sobol)\n",
    "# results_sobol_df.to_excel(\"results_sobol_160s_10p.xlsx\")\n",
    "outcomes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one outcome for testing, do for all outcomes\n",
    "y_welfare = np.mean(outcomes['Welfare'], axis =1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sobol_indices = sobol.analyze(problem, y_welfare)\n",
    "sobol_stats = {k:sobol_indices[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "sobol_stats = pd.DataFrame(sobol_stats, index=problem['names'])\n",
    "# starting with ST\n",
    "sobol_stats.sort_values(by = 'ST', ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the outcomes to Z-scores by using the sobol analyze option\n",
    "welfare_score = sobol.analyze(problem, y_welfare, calc_second_order=True, print_to_console=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Visualize: The error bars indicate the confidence intervals.\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(1)\n",
    "indices = sobol_stats[['S1','ST']]\n",
    "err = sobol_stats[['S1_conf','ST_conf']]\n",
    "\n",
    "indices.plot.bar(yerr=err.values.T,ax=ax)\n",
    "fig.set_size_inches(20,20)\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}