{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shajee\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Shajee\\Anaconda3\\lib\\site-packages\\ema_workbench\\analysis\\prim.py:31: ImportWarning: altair based interactive inspection not available\n",
      "  \"inspection not available\"), ImportWarning)\n",
      "C:\\Users\\Shajee\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Shajee\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Shajee\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Shajee\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "[MainProcess/INFO] pool started\n",
      "[MainProcess/INFO] performing 180000 scenarios * 1 policies * 1 model(s) = 180000 experiments\n",
      "[MainProcess/INFO] 18000 cases completed\n",
      "[MainProcess/INFO] 36000 cases completed\n",
      "[MainProcess/INFO] 54000 cases completed\n",
      "[MainProcess/INFO] 72000 cases completed\n",
      "[MainProcess/INFO] 90000 cases completed\n",
      "[MainProcess/INFO] 108000 cases completed\n",
      "[MainProcess/INFO] 126000 cases completed\n",
      "[MainProcess/INFO] 144000 cases completed\n",
      "[MainProcess/INFO] 162000 cases completed\n",
      "[MainProcess/INFO] 180000 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] terminating pool\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from ema_workbench.analysis import clusterer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from PyDICE_t2xco2 import PyDICE\n",
    "import os\n",
    "os.chdir(os.getcwd())\n",
    "\n",
    "from specify import specify_levers\n",
    "from ema_workbench import (save_results)\n",
    "from ema_workbench import (perform_experiments, Model, Policy, RealParameter, IntegerParameter, ScalarOutcome,\n",
    "                           ema_logging, MultiprocessingEvaluator)\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "model = PyDICE()\n",
    "dice_sm = Model('dicesmEMA', function = model)\n",
    "dice_opt = pd.read_excel(\"DICE2013R.xlsm\" ,sheet_name = \"Opttax\", index_col = 0)\n",
    "\n",
    "dice_sm.uncertainties = [IntegerParameter('t2xco2_index', 0, 999),\n",
    "                         IntegerParameter('t2xco2_dist',0 , 2),\n",
    "                         IntegerParameter('fdamage', 0, 2),\n",
    "                         RealParameter('tfp_gr', 0.07, 0.09),\n",
    "                         RealParameter('sigma_gr', -0.012, -0.008),\n",
    "                         RealParameter('pop_gr', 0.1, 0.15),\n",
    "                         RealParameter('fosslim',  4000.0, 13649),\n",
    "                         IntegerParameter('cback', 100, 600)]\n",
    "\n",
    "dice_sm.levers = [RealParameter('sr', 0.1, 0.5),\n",
    "                  RealParameter('irstp',  0.001, 0.015),\n",
    "                  IntegerParameter('periodfullpart', 10, 58),\n",
    "                  IntegerParameter('miu_period', 10, 58)]\n",
    "\n",
    "\n",
    "dice_sm.outcomes = [ScalarOutcome('ECS', ScalarOutcome.MAXIMIZE),                    \n",
    "                    ScalarOutcome('Utility 2300', ScalarOutcome.MAXIMIZE)]\n",
    "n_scenarios=180000\n",
    "nord_optimal_policy = Policy('nord_optimal_policy', **specify_levers(np.mean(dice_opt.iloc[129]),0.015,0,29))\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "with MultiprocessingEvaluator(dice_sm) as evaluator:\n",
    "    results = evaluator.perform_experiments(scenarios=n_scenarios, policies=nord_optimal_policy)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomesDF = pd.DataFrame(outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resDF = (experiments.T.append(outcomesDF.T)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(resDF[(resDF.t2xco2_dist == 0)][\"t2xco2_index\"] == 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_exp = [[],[],[]]\n",
    "for i in range(3):\n",
    "    list_exp[i] = np.array(resDF[(resDF.t2xco2_dist == i)][\"ECS\"]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm, lognorm, cauchy, wilcoxon\n",
    "import json\n",
    "\n",
    "\n",
    "with open('ecs_dist_v5.json') as f:\n",
    "    d=json.load(f)\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "minb = 0\n",
    "maxb = 20\n",
    "nsamples = 60000\n",
    "\n",
    "samples_norm = np.zeros((0,))\n",
    "while samples_norm.shape[0] < nsamples:\n",
    "    samples = (norm.rvs(d['norm'][0],d['norm'][1],nsamples))\n",
    "    accepted = samples[(samples >= minb) & (samples <= maxb)]\n",
    "    samples_norm = np.concatenate((samples_norm, accepted), axis=0)\n",
    "samples_norm = samples_norm[:nsamples]\n",
    "\n",
    "samples_lognorm = np.zeros((0,))\n",
    "while samples_lognorm.shape[0] < nsamples:\n",
    "    samples = (lognorm.rvs(d['lognorm'][0],d['lognorm'][1],d['lognorm'][2],nsamples))\n",
    "    accepted = samples[(samples >= minb) & (samples <= maxb)]\n",
    "    samples_lognorm = np.concatenate((samples_lognorm, accepted), axis=0)\n",
    "samples_lognorm = samples_lognorm[:nsamples]\n",
    "\n",
    "samples_cauchy = np.zeros((0,))\n",
    "while samples_cauchy.shape[0] < nsamples:\n",
    "    samples = (cauchy.rvs(d['cauchy'][0],d['cauchy'][1],nsamples))\n",
    "    accepted = samples[(samples >= minb) & (samples <= maxb)]\n",
    "    samples_cauchy = np.concatenate((samples_cauchy, accepted), axis=0)\n",
    "samples_cauchy = samples_cauchy[:nsamples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_samples = [samples_norm, samples_lognorm, samples_cauchy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy Comparison of Sampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 0.00032349888222737945\n",
      "Log-Normal: 0.0002984975618048922\n",
      "Cauchy: 0.0008619169349033456\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    x = [\"Normal\",\"Log-Normal\",\"Cauchy\"]\n",
    "    list_samples[i].sort()\n",
    "    list_exp[i].sort()\n",
    "    y = stats.entropy(list_samples[i], list_exp[i])\n",
    "    print(str(x[i])+\": \"+ str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "descDF = pd.DataFrame()\n",
    "for i in range(3):\n",
    "    x = [\"Normal\",\"Log-Normal\",\"Cauchy\"]\n",
    "    sampleDF = pd.DataFrame(list_samples[i], columns=[str(x[i])+\" Sampled Set\"])\n",
    "    descDF = pd.concat([descDF,sampleDF], axis=1)\n",
    "    expDF = pd.DataFrame(list_exp[i], columns=[str(x[i])+\" Experiment Set\"])\n",
    "    descDF = pd.concat([descDF,expDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal Sampled Set</th>\n",
       "      <th>Normal Experiment Set</th>\n",
       "      <th>Log-Normal Sampled Set</th>\n",
       "      <th>Log-Normal Experiment Set</th>\n",
       "      <th>Cauchy Sampled Set</th>\n",
       "      <th>Cauchy Experiment Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.239672</td>\n",
       "      <td>3.201974</td>\n",
       "      <td>3.296763</td>\n",
       "      <td>3.257213</td>\n",
       "      <td>3.535251</td>\n",
       "      <td>3.406725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.409426</td>\n",
       "      <td>1.339230</td>\n",
       "      <td>1.524329</td>\n",
       "      <td>1.516858</td>\n",
       "      <td>2.136046</td>\n",
       "      <td>1.945970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.033768</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.095995</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.024124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>0.299472</td>\n",
       "      <td>0.295406</td>\n",
       "      <td>0.567992</td>\n",
       "      <td>0.461744</td>\n",
       "      <td>0.335904</td>\n",
       "      <td>0.315314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>0.946305</td>\n",
       "      <td>1.027264</td>\n",
       "      <td>1.151042</td>\n",
       "      <td>1.061560</td>\n",
       "      <td>1.218684</td>\n",
       "      <td>1.237627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>1.400381</td>\n",
       "      <td>1.474526</td>\n",
       "      <td>1.512491</td>\n",
       "      <td>1.450988</td>\n",
       "      <td>1.794850</td>\n",
       "      <td>1.859637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.237658</td>\n",
       "      <td>2.287821</td>\n",
       "      <td>2.200395</td>\n",
       "      <td>2.173841</td>\n",
       "      <td>2.556688</td>\n",
       "      <td>2.540184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.211309</td>\n",
       "      <td>3.187206</td>\n",
       "      <td>3.115868</td>\n",
       "      <td>3.101255</td>\n",
       "      <td>3.164942</td>\n",
       "      <td>3.121279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.192123</td>\n",
       "      <td>4.080875</td>\n",
       "      <td>4.181740</td>\n",
       "      <td>4.158097</td>\n",
       "      <td>3.868967</td>\n",
       "      <td>3.723525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>5.078002</td>\n",
       "      <td>4.929140</td>\n",
       "      <td>5.315707</td>\n",
       "      <td>5.234249</td>\n",
       "      <td>5.312842</td>\n",
       "      <td>4.790421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>5.618523</td>\n",
       "      <td>5.378633</td>\n",
       "      <td>6.076151</td>\n",
       "      <td>6.011506</td>\n",
       "      <td>7.116611</td>\n",
       "      <td>6.245218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>6.608209</td>\n",
       "      <td>6.605479</td>\n",
       "      <td>7.702322</td>\n",
       "      <td>7.521958</td>\n",
       "      <td>13.459057</td>\n",
       "      <td>11.798592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.315586</td>\n",
       "      <td>7.138179</td>\n",
       "      <td>13.807649</td>\n",
       "      <td>11.604384</td>\n",
       "      <td>19.997787</td>\n",
       "      <td>19.782951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Normal Sampled Set  Normal Experiment Set  Log-Normal Sampled Set  \\\n",
       "count        60000.000000           60000.000000            60000.000000   \n",
       "mean             3.239672               3.201974                3.296763   \n",
       "std              1.409426               1.339230                1.524329   \n",
       "min              0.000676               0.033768                0.000436   \n",
       "1%               0.299472               0.295406                0.567992   \n",
       "5%               0.946305               1.027264                1.151042   \n",
       "10%              1.400381               1.474526                1.512491   \n",
       "25%              2.237658               2.287821                2.200395   \n",
       "50%              3.211309               3.187206                3.115868   \n",
       "75%              4.192123               4.080875                4.181740   \n",
       "90%              5.078002               4.929140                5.315707   \n",
       "95%              5.618523               5.378633                6.076151   \n",
       "99%              6.608209               6.605479                7.702322   \n",
       "max              9.315586               7.138179               13.807649   \n",
       "\n",
       "       Log-Normal Experiment Set  Cauchy Sampled Set  Cauchy Experiment Set  \n",
       "count               60000.000000        60000.000000           60000.000000  \n",
       "mean                    3.257213            3.535251               3.406725  \n",
       "std                     1.516858            2.136046               1.945970  \n",
       "min                     0.095995            0.000059               0.024124  \n",
       "1%                      0.461744            0.335904               0.315314  \n",
       "5%                      1.061560            1.218684               1.237627  \n",
       "10%                     1.450988            1.794850               1.859637  \n",
       "25%                     2.173841            2.556688               2.540184  \n",
       "50%                     3.101255            3.164942               3.121279  \n",
       "75%                     4.158097            3.868967               3.723525  \n",
       "90%                     5.234249            5.312842               4.790421  \n",
       "95%                     6.011506            7.116611               6.245218  \n",
       "99%                     7.521958           13.459057              11.798592  \n",
       "max                    11.604384           19.997787              19.782951  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descDF.describe(percentiles = [0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
